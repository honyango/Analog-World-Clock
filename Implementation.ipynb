{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16a5F7Xmx4oVFnxTf67aGXWc5kq7rBCro",
      "authorship_tag": "ABX9TyNtnbd3vS02HoYEAhKi3Ybi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honyango/Analog-World-Clock/blob/master/Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pipeline"
      ],
      "metadata": {
        "id": "OzeG9e_JIthQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTDJxhgTIsuj",
        "outputId": "62408592-cbee-4785-93f4-b3328fe69e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Mount Drive and load CSV (example for train)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/Alzheimers Detection Dataset/Alzheimers_Detection_dataset'\n",
        "train_df = pd.read_csv(os.path.join(base_path, 'CSV_datafiles', '_train_classes.csv'))\n",
        "\n",
        "class AlzheimerDataset(Dataset):\n",
        "    def __init__(self, df, folder, transform=None):\n",
        "        self.df = df\n",
        "        self.folder = folder\n",
        "        self.transform = transform\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.df.iloc[idx]['filename']\n",
        "        img_path = os.path.join(self.base_path, self.folder, filename)\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if image is None:\n",
        "            # Handle cases where image loading fails\n",
        "            # For now, we'll raise an error, but in a real pipeline, you might want to skip or log.\n",
        "            raise ValueError(f\"Image not found or corrupted: {img_path}\")\n",
        "\n",
        "        # Ensure image is 3-channel. If grayscale (2D), convert to BGR first.\n",
        "        if image.ndim == 2:  # Grayscale image\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Now 'image' is guaranteed to be 3-channel BGR, so convert to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        label = self.df.iloc[idx, 1:].values.argmax()  # Class index (for classification; adapt for mask)\n",
        "        # Placeholder mask: Create with same dimensions as image\n",
        "        mask = torch.zeros((image.shape[0], image.shape[1])) # Dynamically size mask to match image\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask.numpy())\n",
        "            image = augmented['image'] # This is now a torch.Tensor in CHW format\n",
        "            mask = augmented['mask']   # This is now a torch.Tensor\n",
        "\n",
        "        return image.float(), mask.long(), label # Directly return the tensors from augmented\n",
        "\n",
        "# Transforms with albumentations (pip install albumentations)\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Normalize(mean=0.5, std=0.5),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "train_dataset = AlzheimerDataset(train_df, 'train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Instantiation"
      ],
      "metadata": {
        "id": "015LpsAWJEGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1):\n",
        "        super(UNet, self).__init__()\n",
        "        # Encoder: Conv blocks with maxpool\n",
        "        self.enc1 = self.conv_block(n_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        # Placeholder for full UNet architecture. Let's complete a simple one for demonstration.\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "        self.enc5 = self.conv_block(512, 1024)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.dec4 = self.conv_block(1024, 512)\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = self.conv_block(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = self.conv_block(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = self.conv_block(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, n_classes, 1)\n",
        "\n",
        "    def conv_block(self, in_c, out_c):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x) # 64\n",
        "        p1 = self.pool1(e1)\n",
        "        e2 = self.enc2(p1) # 128\n",
        "        p2 = self.pool2(e2)\n",
        "        e3 = self.enc3(p2) # 256\n",
        "        p3 = self.pool3(e3)\n",
        "        e4 = self.enc4(p3) # 512\n",
        "        p4 = self.pool4(e4)\n",
        "        e5 = self.enc5(p4) # 1024\n",
        "\n",
        "        # Decoder\n",
        "        d4 = self.up4(e5) # 512\n",
        "        d4 = torch.cat((e4, d4), dim=1) # 1024\n",
        "        d4 = self.dec4(d4) # 512\n",
        "\n",
        "        d3 = self.up3(d4) # 256\n",
        "        d3 = torch.cat((e3, d3), dim=1) # 512\n",
        "        d3 = self.dec3(d3) # 256\n",
        "\n",
        "        d2 = self.up2(d3) # 128\n",
        "        d2 = torch.cat((e2, d2), dim=1) # 256\n",
        "        d2 = self.dec2(d2) # 128\n",
        "\n",
        "        d1 = self.up1(d2) # 64\n",
        "        d1 = torch.cat((e1, d1), dim=1) # 128\n",
        "        d1 = self.dec1(d1) # 64\n",
        "\n",
        "        return torch.sigmoid(self.out(d1))\n",
        "\n",
        "# Dynamically select device (GPU if available, else CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "model = UNet().to(device) # Move model to selected device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HNGz6s6JEgL",
        "outputId": "b98b5715-8541-418c-fbbe-6435bc499c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "0LTiwD69JXAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "for epoch in range(10):  # Example epochs\n",
        "    model.train()\n",
        "    for images, masks, _ in train_loader:\n",
        "        # Move tensors to the selected device\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # Validation similarly, compute metrics\n",
        "\n",
        "\n",
        "    model.eval()"
      ],
      "metadata": {
        "id": "ysEbK-pYJXZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rCPI0OFsLTCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import jaccard_score  # Or custom Dice\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, masks, _ in test_loader:\n",
        "        outputs = model(images.cuda())\n",
        "        preds = (outputs > 0.5).float()\n",
        "        # Compute Dice: 2 * (pred & gt).sum() / (pred.sum() + gt.sum())"
      ],
      "metadata": {
        "id": "MWVVvzG1LTZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5abac496",
        "outputId": "90c94851-b1e5-4677-e9ae-905ca6697b38"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Mount Drive and load CSV (example for train)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/Alzheimers Detection Dataset/Alzheimers_Detection_dataset'\n",
        "train_df = pd.read_csv(os.path.join(base_path, 'CSV_datafiles', '_train_classes.csv'))\n",
        "test_df = pd.read_csv(os.path.join(base_path, 'CSV_datafiles', '_test_classes.csv'))\n",
        "\n",
        "class AlzheimerDataset(Dataset):\n",
        "    def __init__(self, df, folder, transform=None):\n",
        "        self.df = df\n",
        "        self.folder = folder\n",
        "        self.transform = transform\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.df.iloc[idx]['filename']\n",
        "        img_path = os.path.join(self.base_path, self.folder, filename)\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if image is None:\n",
        "            # Handle cases where image loading fails\n",
        "            # For now, we'll raise an error, but in a real pipeline, you might want to skip or log.\n",
        "            raise ValueError(f\"Image not found or corrupted: {img_path}\")\n",
        "\n",
        "        # Ensure image is 3-channel. If grayscale (2D), convert to BGR first.\n",
        "        if image.ndim == 2:  # Grayscale image\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Now 'image' is guaranteed to be 3-channel BGR, so convert to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        label = self.df.iloc[idx, 1:].values.argmax()  # Class index (for classification; adapt for mask)\n",
        "        # Placeholder mask: Create with same dimensions as image\n",
        "        mask = torch.zeros((image.shape[0], image.shape[1])) # Dynamically size mask to match image\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask.numpy())\n",
        "            image = augmented['image'] # This is now a torch.Tensor in CHW format\n",
        "            mask = augmented['mask']   # This is now a torch.Tensor\n",
        "\n",
        "        return image.float(), mask.long(), label # Directly return the tensors from augmented\n",
        "\n",
        "# Transforms with albumentations (pip install albumentations)\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Normalize(mean=0.5, std=0.5),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "train_dataset = AlzheimerDataset(train_df, 'train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataset = AlzheimerDataset(test_df, 'test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c7128ea"
      },
      "source": [
        "from sklearn.metrics import jaccard_score  # Or custom Dice\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, masks, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = (outputs > 0.5).float()\n",
        "        # Compute Dice: 2 * (pred & gt).sum() / (pred.sum() + gt.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "cKIILMMGQH9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/Alzheimers Detection Dataset/Alzheimers_Detection_dataset'\n",
        "test_df = pd.read_csv(base_path + '_test_classes.csv')\n",
        "class_counts = test_df[['MD', 'MoD', 'ND', 'VMD']].sum()\n",
        "print(class_counts)  # Outputs: MD 84, MoD 5, ND 319, VMD 230\n",
        "\n",
        "# For metrics (post-training, with preds and gts as tensors)\n",
        "from torchmetrics import Dice, JaccardIndex, Precision\n",
        "dice = Dice().cuda()\n",
        "iou = JaccardIndex(task='binary').cuda()\n",
        "prec = Precision(task='binary').cuda()\n",
        "# In eval loop: dice(preds, gts), etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "e_8XjletQGyG",
        "outputId": "02f7929a-29e2-4749-9a06-fed4063cbddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Alzheimers Detection Dataset/Alzheimers_Detection_dataset_test_classes.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2619908894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Alzheimers Detection Dataset/Alzheimers_Detection_dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_test_classes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MoD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ND'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VMD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Outputs: MD 84, MoD 5, ND 319, VMD 230\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Alzheimers Detection Dataset/Alzheimers_Detection_dataset_test_classes.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/Alzheimers Detection Dataset/Alzheimers_Detection_dataset'\n",
        "\n",
        "# --- Diagnosing the FileNotFoundError ---\n",
        "# Let's list the contents of the directory to verify the file path and name.\n",
        "# This line will help you see if '_test_classes.csv' or a similar file exists.\n",
        "# import os\n",
        "# print(os.listdir(base_path))\n",
        "\n",
        "# Original line causing error:\n",
        "# test_df = pd.read_csv(base_path + '_test_classes.csv')\n",
        "\n",
        "# Assuming the file path is corrected, the rest of the code will follow.\n",
        "# class_counts = test_df[['MD', 'MoD', 'ND', 'VMD']].sum()\n",
        "# print(class_counts)  # Outputs: MD 84, MoD 5, ND 319, VMD 230\n",
        "\n",
        "# For metrics (post-training, with preds and gts as tensors)\n",
        "\n",
        "!pip install torchmetrics # Install the missing library\n",
        "\n",
        "from torchmetrics.classification import Dice\n",
        "from torchmetrics import JaccardIndex, Precision\n",
        "dice = Dice().cuda()\n",
        "iou = JaccardIndex(task='binary').cuda()\n",
        "prec = Precision(task='binary').cuda()\n",
        "# In eval loop: dice(preds, gts), etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "dhX9jV19RqI-",
        "outputId": "07a3d2ea-2908-4dd4-ecdb-1618f6ba2488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cpu)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Dice' from 'torchmetrics.classification' (/usr/local/lib/python3.12/dist-packages/torchmetrics/classification/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3245505719.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torchmetrics # Install the missing library'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJaccardIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Dice' from 'torchmetrics.classification' (/usr/local/lib/python3.12/dist-packages/torchmetrics/classification/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}